{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 활성화 함수 사용(Activation fuction)\n",
    " - 경사손실 문제를 해결하기 위해 도함수의 값이 1보다 작지 않은 값을 사용해보자\n",
    " - 쌍곡탄젠트(tanh), ReLU, LeakyReLu, Parametric ReLU, Randomized ReLU 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현 예시\n",
    " - MNIST를 사용해 쌍곡탄젠트(tanh)를 사용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:85: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:85: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "\n",
    "mnist = datasets.fetch_mldata('MNIST original', data_home='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(mnist.data)\n",
    "N = 10000\n",
    "indices = np.random.permutation(range(n))[:N]\n",
    "X = mnist.data[indices]\n",
    "y = mnist.target[indices]\n",
    "Y = np.eye(10)[y.astype(int)]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 1.4876 - accuracy: 0.5630\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.8387 - accuracy: 0.7840\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.6469 - accuracy: 0.8361\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.5514 - accuracy: 0.8503\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4817 - accuracy: 0.8669\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4356 - accuracy: 0.8815\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3973 - accuracy: 0.8882\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3786 - accuracy: 0.8947\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3759 - accuracy: 0.8936\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3535 - accuracy: 0.9010\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3303 - accuracy: 0.9069\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3190 - accuracy: 0.9105\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3142 - accuracy: 0.9085\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 1s 170us/step - loss: 0.3135 - accuracy: 0.9116\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.2928 - accuracy: 0.9140\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.2879 - accuracy: 0.9197\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 2s 229us/step - loss: 0.2773 - accuracy: 0.9160\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 4s 498us/step - loss: 0.2548 - accuracy: 0.9268\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 3s 434us/step - loss: 0.2489 - accuracy: 0.9300\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 0.2486 - accuracy: 0.9294\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 3s 390us/step - loss: 0.2443 - accuracy: 0.9280\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.2485 - accuracy: 0.9300\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.2337 - accuracy: 0.9339\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.2352 - accuracy: 0.9316\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.2286 - accuracy: 0.9354\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.2284 - accuracy: 0.9350\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.2402 - accuracy: 0.9298\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.2413 - accuracy: 0.9291\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.2384 - accuracy: 0.9299\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.2450 - accuracy: 0.9269\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.2336 - accuracy: 0.9314\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.2310 - accuracy: 0.9310\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.2220 - accuracy: 0.9320\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.2193 - accuracy: 0.9352\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.2230 - accuracy: 0.9352\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.2193 - accuracy: 0.9341\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.2299 - accuracy: 0.9302\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.2270 - accuracy: 0.9325\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.2030 - accuracy: 0.9426\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.2024 - accuracy: 0.9430\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.1995 - accuracy: 0.9395\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.1922 - accuracy: 0.9427\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.1948 - accuracy: 0.9435\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.1976 - accuracy: 0.9415\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 1s 167us/step - loss: 0.1982 - accuracy: 0.9408\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.2069 - accuracy: 0.9376\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.1950 - accuracy: 0.9433\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.1978 - accuracy: 0.9399\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.1948 - accuracy: 0.9419\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.1993 - accuracy: 0.9379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x3bf1dec8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = len(X[0]) # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0]) # 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim=n_in))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 200us/step\n",
      "[0.31854230296611785, 0.9024999737739563]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과\n",
    " - 정확도 약 90%정도로 잘 학습된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현 예시\n",
    " - 이번에는 Keras오 ReLU를 이용하여 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 2s 263us/step - loss: 5.0304 - accuracy: 0.6199\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 1.0185 - accuracy: 0.8173\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.5913 - accuracy: 0.8733\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.3731 - accuracy: 0.9103\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 0.2515 - accuracy: 0.9359\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.1709 - accuracy: 0.9592\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.1201 - accuracy: 0.9735\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 1s 122us/step - loss: 0.0883 - accuracy: 0.9822\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 1s 131us/step - loss: 0.0672 - accuracy: 0.9881\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 1s 115us/step - loss: 0.0517 - accuracy: 0.9927\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 1s 120us/step - loss: 0.0395 - accuracy: 0.9941\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.0308 - accuracy: 0.9965\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.0249 - accuracy: 0.9975\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.0205 - accuracy: 0.9979\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.0171 - accuracy: 0.99911s - los\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0149 - accuracy: 0.9994\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0131 - accuracy: 0.9996\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.0117 - accuracy: 0.9999\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.0106 - accuracy: 0.9999\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.0096 - accuracy: 0.9999\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 3s 401us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 4s 510us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 4s 476us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 3s 416us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 2s 223us/step - loss: 0.0039 - accuracy: 1.00004s - loss: - ETA: 1s - los\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.0029 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x4bb44088>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = len(X[0]) # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0]) # 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim=n_in))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 50, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 95us/step\n",
      "[0.8623080580309034, 0.8694999814033508]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과\n",
    " - 저의 경우에는 학습률을 지난 모델처럼 0.1이나 0.01수준으로 두면 loss가 nan값이 나오고 정확도가 1%정도로 학습에 실패하였습니다. 이 때 학습률을 0.001정도로 하였더니 학습이 원할이 진행된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현 예시\n",
    " - LeakyReLU를 이용하여 모델을 구현해보겠습니다.\n",
    " - tensorflow에는 LeakyReLU에 대해 정의된 함수가 없어 사용자가 직접 수식으로 정의해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(x, alpha=0.01):\n",
    "    return tf.maximum(alpha * x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 3\n",
    "n_in = len(X[0]) # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0]) # 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "\n",
    "#입력층 - 은닉층\n",
    "W0 = tf.Variable(tf.truncated_normal([n_in, n_hidden], stddev=0.01))\n",
    "b0 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h0 = lrelu(tf.matmul(x, W0) + b0)\n",
    "\n",
    "#은닉층 - 은닉층\n",
    "W1 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h1 = lrelu(tf.matmul(h0, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h2 = lrelu(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h3 = lrelu(tf.matmul(h2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([n_hidden, n_out], stddev=0.01))\n",
    "b4 = tf.Variable(tf.zeros([n_out]))\n",
    "y = tf.nn.softmax(tf.matmul(h3, W4) + b4)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(t * tf.log(y) + (1-t)*tf.log(y-1))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.to_float(tf.greater(y, 0.5)), t)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "n_batches = 100\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(50):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end]\n",
    "        })\n",
    "    print('epoch:', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test\n",
    "})\n",
    "print('accuracy: ', accuracy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과\n",
    " - 잘 학습됐습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 캐라스로 학습\n",
    " - LeakyReLU를 케라스로 학습해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU # 케라스에는 텐서플로우랑 달리 함수가 정의되어 있어 불러오기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 114us/step - loss: 5.0354 - accuracy: 0.6185\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.9892 - accuracy: 0.8171\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.5944 - accuracy: 0.8687\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3803 - accuracy: 0.9066\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.2639 - accuracy: 0.9311\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.1800 - accuracy: 0.9520\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.1315 - accuracy: 0.9665\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.0944 - accuracy: 0.9771\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.0707 - accuracy: 0.9839\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.0542 - accuracy: 0.9898\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 2s 238us/step - loss: 0.0428 - accuracy: 0.9925\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 4s 455us/step - loss: 0.0348 - accuracy: 0.9948\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 5s 672us/step - loss: 0.0286 - accuracy: 0.99690s - los\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 3s 428us/step - loss: 0.0239 - accuracy: 0.9979\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 3s 372us/step - loss: 0.0204 - accuracy: 0.99830s - loss: 0.0195 - accura\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.0181 - accuracy: 0.9987\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.0157 - accuracy: 0.9992\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.0140 - accuracy: 0.9996\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.0126 - accuracy: 0.9996\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.0115 - accuracy: 0.9998\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.0105 - accuracy: 0.9998\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 1s 173us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 1s 97us/step - loss: 0.0033 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x4bf25d88>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = len(X[0]) # 784\n",
    "n_hidden = 200\n",
    "n_out = len(Y[0]) # 10\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim=n_in))\n",
    "model.add(LeakyReLU(alpha=alpha))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(LeakyReLU(alpha=alpha))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(LeakyReLU(alpha=alpha))\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(LeakyReLU(alpha=alpha))\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs = 50, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 107us/step\n",
      "[0.7001358628123998, 0.8654999732971191]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과\n",
    " - 학습이 잘 진행됐습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현예시\n",
    " - Parametric 함수를 이용하여 모델을 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prelu(x, alpha):\n",
    "    return tf.maximum(tf.zeros(tf.shape(x)), x) + alpha * tf.minimum(tf.zeros(tf.shape(x)), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력층 - 은닉층\n",
    "W0 = tf.Variable(tf.truncated_normal([n_in, n_hidden], stddev=0.01))\n",
    "b0 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha0 = tf.Variable(tf.zeros(n_hidden))\n",
    "h0 = prelu(tf.matmul(x, W0) + b0, alpha0)\n",
    "# 은닉층 - 은닉층\n",
    "W1 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h1 = prelu(tf.matmul(h0, W1) + b1, alpha1)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha2 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h2 = prelu(tf.matmul(h1, W2) + b2, alpha2)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=0.01))\n",
    "b3 = tf.Variable(tf.zeros([n_hidden]))\n",
    "alpha3 = tf.Variable(tf.zeros([n_hidden]))\n",
    "h3 = prelu(tf.matmul(h2, W3) + b3, alpha3)\n",
    "\n",
    "# 은닉층 - 출력층\n",
    "W4 = tf.Variable(tf.truncated_normal([n_hidden, n_out], stddev=0.01))\n",
    "b4 = tf.Variable(tf.zeros([n_out]))\n",
    "y = tf.nn.softmax(tf.matmul(h3, W4) + b4)\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(t * tf.log(y) + (1-t)*tf.log(y-1))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.to_float(tf.greater(y, 0.5)), t)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "n_batches = 100\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(50):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end]\n",
    "        })\n",
    "    print('epoch:', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "accuracy_rate = accuracy.eval(session=sess, feed_dict={\n",
    "    x: X_test,\n",
    "    t: Y_test\n",
    "})\n",
    "print('accuracy: ', accuracy_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과\n",
    " - 학습이 잘 됐습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 5.4273 - accuracy: 0.6215\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 1s 187us/step - loss: 1.0057 - accuracy: 0.8155\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.5756 - accuracy: 0.8755\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 1s 121us/step - loss: 0.3737 - accuracy: 0.9075\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.2499 - accuracy: 0.9375\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 0.1707 - accuracy: 0.9545\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.1151 - accuracy: 0.9720\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.0802 - accuracy: 0.9825\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.0569 - accuracy: 0.9887\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.0419 - accuracy: 0.9940\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 1s 99us/step - loss: 0.0322 - accuracy: 0.9958\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 1s 107us/step - loss: 0.0250 - accuracy: 0.9976\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.0205 - accuracy: 0.9985\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 1s 117us/step - loss: 0.0172 - accuracy: 0.9998\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 1s 116us/step - loss: 0.0149 - accuracy: 0.9999\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.0132 - accuracy: 0.9999\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.0118 - accuracy: 0.9999\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.0108 - accuracy: 0.9999\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 1s 180us/step - loss: 0.0099 - accuracy: 0.9999\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 1s 113us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 1s 108us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8000/8000 [==============================] - 2s 258us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8000/8000 [==============================] - 6s 714us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8000/8000 [==============================] - 4s 531us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8000/8000 [==============================] - 5s 602us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8000/8000 [==============================] - 1s 101us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8000/8000 [==============================] - 1s 103us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8000/8000 [==============================] - 1s 112us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8000/8000 [==============================] - 2s 190us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8000/8000 [==============================] - 1s 106us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8000/8000 [==============================] - 1s 118us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8000/8000 [==============================] - 1s 111us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8000/8000 [==============================] - 1s 102us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8000/8000 [==============================] - 1s 105us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8000/8000 [==============================] - 1s 124us/step - loss: 0.0029 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x4edd3dc8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden, input_dim=n_in))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(n_hidden))\n",
    "model.add(PReLU())\n",
    "\n",
    "model.add(Dense(n_out))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 159us/step\n",
      "[0.7427099406421185, 0.8765000104904175]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized ReLU\n",
    " - Randomized ReLU를 따로 실습하지는 않지만 언급을 하자면 학습할 때 경사 자체를 난수로 선택학 테스트를 할 때는 그 평균을 사용하는 방식입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
